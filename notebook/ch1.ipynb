{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "import os\n",
    "import random\n",
    "from enum import Enum\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nptyping import NDArray\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "colors = ['#de3838', '#007bc3', '#ffd12a']\n",
    "markers = ['o', 'x', ',']\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 100)\n",
    "\n",
    "cmap = sns.diverging_palette(255, 0, as_cmap=True)  # カラーパレットの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action(Enum):\n",
    "    UP = 1\n",
    "    DOWN = -1\n",
    "    LEFT = 2\n",
    "    RIGHT = -2\n",
    "\n",
    "\n",
    "class State:\n",
    "    def __init__(self, row: int = -1, col: int = -1) -> None:\n",
    "        self.row : int = row\n",
    "        self.col : int = col\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f'<State: [{self.row}, {self.col}]>'\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        return hash((self.row, self.col))\n",
    "    \n",
    "    def __eq__(self, other: object) -> bool:\n",
    "        return (self.row == other.row) and (self.col == other.col)\n",
    "    \n",
    "    def clone(self) -> object:\n",
    "        return State(row=self.row, col=self.col)\n",
    "\n",
    "\n",
    "class Environment:\n",
    "    def __init__(self, grid: List[List[int]], move_prob: float = 0.8) -> None:\n",
    "        # grid is 2d-array. Its values are treated as an attribute.\n",
    "        # Kinds of attribute is following.\n",
    "        #  0: ordinary cell\n",
    "        #  -1: damage cell (game end)\n",
    "        #  1: reward cell (game end)\n",
    "        #  9: block cell (can't locate agent)\n",
    "        self.grid : List[List[int]] = grid\n",
    "        self.agent_state : State = State()\n",
    "\n",
    "        # Default reward is minus. Just like a poison swamp.\n",
    "        # It means the agent has to reach the goal fast!\n",
    "        self.default_reward : float = -0.04\n",
    "\n",
    "        # Agent can move to a selected direction in move_prob.\n",
    "        # It means the agent will move different direction\n",
    "        # in (1 - move_prob).\n",
    "        self.move_prob : float = move_prob\n",
    "        self.reset()\n",
    "\n",
    "    @property\n",
    "    def row_length(self) -> int:\n",
    "        return len(self.grid)\n",
    "\n",
    "    @property\n",
    "    def col_length(self) -> int:\n",
    "        return len(self.grid[0])\n",
    "    \n",
    "    @property\n",
    "    def actions(self) -> List[Action]:\n",
    "        \"\"\"取り得る全てのアクション\"\"\"\n",
    "        return [Action.UP, Action.DOWN, Action.LEFT, Action.RIGHT]\n",
    "\n",
    "    @property\n",
    "    def states(self) -> List[State]:\n",
    "        \"\"\"取り得る全ての状態\"\"\"\n",
    "        states : List[List[int]] = [State(row=row, col=col) for row in range(self.row_length) for col in range(self.col_length)]\n",
    "        return states\n",
    "\n",
    "    def transit_func(self, state: State, action: Action) -> Dict[State, float]:\n",
    "        transition_probs : Dict[State, float] = {}\n",
    "        if not self.can_action_at(state=state):\n",
    "            # Already on the terminal cell.\n",
    "            return transition_probs\n",
    "        \n",
    "        opposite_direction : Action = Action(action.value * -1)\n",
    "\n",
    "        for a in self.actions:\n",
    "            prob : float = 0\n",
    "            if a == action:\n",
    "                prob = self.move_prob\n",
    "            elif a != opposite_direction:\n",
    "                prob = (1 - self.move_prob) / 2\n",
    "            \n",
    "            next_state = self._move(state, a)\n",
    "            if next_state not in transition_probs:\n",
    "                transition_probs[next_state] = prob\n",
    "            else:\n",
    "                transition_probs[next_state] += prob\n",
    "            \n",
    "        return transition_probs\n",
    "\n",
    "\n",
    "    def can_action_at(self, state: State) -> bool:\n",
    "        if self.grid[state.row][state.col] == 0:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def _move(self, state: State, action: Action) -> State:\n",
    "        if not self.can_action_at(state=state):\n",
    "            raise Exception('Can\\'t move from here!')\n",
    "        \n",
    "        next_state : State = state.clone()\n",
    "\n",
    "        # Execute an action (move)\n",
    "        if action == Action.UP:\n",
    "            next_state.row -= 1\n",
    "        elif action == Action.DOWN:\n",
    "            next_state.row += 1\n",
    "        elif action == Action.LEFT:\n",
    "            next_state.col -= 1\n",
    "        elif action == Action.RIGHT:\n",
    "            next_state.col += 1\n",
    "\n",
    "        # Check whether a state is out of the grid.\n",
    "        if not (0 <= next_state.row < self.row_length):\n",
    "            next_state = state\n",
    "        if not (0 <= next_state.col < self.col_length):\n",
    "            next_state = state\n",
    "\n",
    "        # Check whether the agent bumped a block cell.\n",
    "        if self.grid[next_state.row][next_state.col] == 9:\n",
    "            next_state = state\n",
    "        \n",
    "        return next_state\n",
    "\n",
    "    def reward_func(self, state: State) -> Tuple[float, bool]:\n",
    "        reward : float = self.default_reward\n",
    "        done : bool = False\n",
    "\n",
    "        # Check an attribute of next state.\n",
    "        attribute : int = self.grid[state.row][state.col]\n",
    "        if attribute == 1:\n",
    "            # Get reward! and the game ends.\n",
    "            reward = 1\n",
    "            done = True\n",
    "        if attribute == -1:\n",
    "            # Get damage! and the game ends.\n",
    "            reward = -1\n",
    "            done = True\n",
    "        \n",
    "        return reward, done\n",
    "\n",
    "    def reset(self) -> State:\n",
    "        # Locate the agent at lower left corner.\n",
    "        self.agent_state = State(row=self.row_length - 1, col=0)\n",
    "        return self.agent_state\n",
    "\n",
    "    def step(self, action: Action) -> Tuple[Optional[State], Optional[float], bool]:\n",
    "        next_state, reward, done = self.transit(state=self.agent_state, action=action)\n",
    "        if next_state is not None:\n",
    "            self.agent_state = next_state\n",
    "        return next_state, reward, done\n",
    "\n",
    "    def transit(self, state: State, action: Action) -> Tuple[Optional[State], Optional[float], bool]:\n",
    "        transition_probs : Dict[State, float] = self.transit_func(state=state, action=action)\n",
    "        if len(transition_probs) == 0:\n",
    "            return None, None, True\n",
    "\n",
    "        next_states : List[State] = []\n",
    "        probs : List[float] = []\n",
    "        for s in transition_probs:\n",
    "            next_states.append(s)\n",
    "            probs.append(transition_probs[s])\n",
    "        \n",
    "        next_state : State = np.random.choice(next_states, p=probs)\n",
    "        reward, done = self.reward_func(state=next_state)\n",
    "        return next_state, reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0: Agent gets 0.52 reward.\n",
      "Episode 1: Agent gets -2.28 reward.\n",
      "Episode 2: Agent gets -1.64 reward.\n",
      "Episode 3: Agent gets -2.72 reward.\n",
      "Episode 4: Agent gets -1.92 reward.\n",
      "Episode 5: Agent gets 0.48 reward.\n",
      "Episode 6: Agent gets 0.64 reward.\n",
      "Episode 7: Agent gets -2.84 reward.\n",
      "Episode 8: Agent gets -0.28 reward.\n",
      "Episode 9: Agent gets 0.36 reward.\n"
     ]
    }
   ],
   "source": [
    "class Agent:\n",
    "    def __init__(self, env: Environment) -> None:\n",
    "        self.actions : List[Action] = env.actions\n",
    "    \n",
    "    def policy(self, state: State) -> Action:\n",
    "        return random.choice(self.actions)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Make grid environment.\n",
    "    grid : List[List[int]] = [\n",
    "        [0, 0, 0, 1],\n",
    "        [0, 9, 0, -1],\n",
    "        [0, 0, 0, 0]\n",
    "    ]\n",
    "    env : Environment = Environment(grid=grid)\n",
    "    agent : Agent = Agent(env=env)\n",
    "\n",
    "    # Try 10 game.\n",
    "    for i in range(10):\n",
    "        # Initialize position of agent.\n",
    "        state : State = env.reset()\n",
    "        total_reward : float = 0\n",
    "        done : bool = False\n",
    "\n",
    "        while not done:\n",
    "            action : Action = agent.policy(state=state)\n",
    "            next_state, reward, done = env.step(action=action)\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "\n",
    "        print(f'Episode {i}: Agent gets {total_reward:.2f} reward.')\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50bb28d91d8964d6677cc2a0866425352867b335ef92d97f6303b8ea15a1963f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('rl': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
